Usage

1. Virtual Mouse

Run the virtual mouse script:

python virtual_mouse.py

Follow on-screen instructions to use gestures for cursor control.

2. Body Language Detector

Run the body language detection script:

python body_language_detector.py

Stand in front of the camera, and the tool will analyze your posture and gestures.

3. Facial ID Recognition

Run the facial ID recognition script:

python facial_id_recognition.py

Load a database of faces, and the software will detect and identify faces in real-time.

Configuration

Adjust parameters like camera resolution, tracking sensitivity, and gesture mappings in the respective configuration files (config_virtual_mouse.json, config_body_language.json, etc.).

Integrate custom facial databases by adding images to the faces/ directory and updating faces_db.json.

Contributions

Contributions are welcome! If you have ideas for new tools or improvements, feel free to fork the repository and create a pull request. Please ensure your contributions align with the coding style and include documentation.

License

This project is licensed under the MIT License. See the LICENSE file for details.

Acknowledgments

Mediapipe for providing powerful tracking algorithms.

OpenCV for robust computer vision tools.

The open-source community for their contributions and support.

Future Work

Add support for voice commands integrated with gesture controls.

Implement multi-user tracking for collaborative applications.

Develop a desktop app for easier access and configuration.

Start exploring the capabilities of face, hand, and body tracking with this versatile tool suite!
